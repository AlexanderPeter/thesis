{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet50\n",
    "from transformers import ViTModel\n",
    "\n",
    "sys.path.append(\"ssl_library\")\n",
    "from src.pkg.embedder import Embedder\n",
    "from src.pkg.wrappers import ViTWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 19\n",
    "img_size = 224\n",
    "batch_size = 16\n",
    "normalise_mean = (0.485, 0.456, 0.406)  # ImageNet\n",
    "normalise_std = (0.229, 0.224, 0.225)  # ImageNet\n",
    "\n",
    "configuration_csv_path = \"configs/tasks-configuration-new.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17340ce3cb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 960\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()\n",
    "n_devices = torch.cuda.device_count()\n",
    "for i in range(0, n_devices):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_architecture, checkpoint_path):\n",
    "    model = None\n",
    "\n",
    "    if model_architecture == \"resnet50\":\n",
    "        print(f\"Implement!\")\n",
    "    elif model_architecture == \"swin_t\":\n",
    "        print(f\"Implement!\")\n",
    "    elif model_architecture == \"vit_b16\":\n",
    "        print(f\"Implement!\")\n",
    "    elif model_architecture == \"ViT_T16\":\n",
    "        if \"vit_t16_v1\" in checkpoint_path:\n",
    "            model = Embedder.load_pretrained(\"imagenet_vit_tiny\")\n",
    "        elif \"vit_t16_v2\" in checkpoint_path:\n",
    "            model = Embedder.load_pretrained(\"vit_tiny_random\")\n",
    "        elif \"vit_t16_v3\" in checkpoint_path:\n",
    "            # NOTE: VisionTransformer from timm neds to be wrapped to get intermediate results\n",
    "            model = timm.create_model(\"vit_tiny_patch16_224\", pretrained=False)\n",
    "            model = ViTWrapper(model)\n",
    "        model.head = nn.Sequential()\n",
    "    else:\n",
    "        print(f\"Unknown model architecture: {model_architecture}\")\n",
    "        return None\n",
    "\n",
    "    assert model != None\n",
    "    print(f\"Loading {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(checkpoint, strict=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderExtented(datasets.ImageFolder):\n",
    "    # NOTE: ImageFolder uses pil_loader as default, which executes Image.convert(\"RGB\") implicitly\n",
    "    def __getitem__(self, index: int):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target, os.path.basename(path)\n",
    "\n",
    "\n",
    "def load_dataloader(data_dir):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.CenterCrop(img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(normalise_mean, normalise_std),\n",
    "        ]\n",
    "    )\n",
    "    ds_full = ImageFolderExtented(data_dir, transform=transform)\n",
    "\n",
    "    dl_full = data.DataLoader(\n",
    "        ds_full,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "    )\n",
    "    return dl_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(model, dl_full):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    target_list = []\n",
    "    features_list = []\n",
    "    filename_list = []\n",
    "\n",
    "    for i, (images, targets, filenames) in enumerate(dl_full):\n",
    "        # print(f\"Batch {i}\")\n",
    "        filename_list.extend(filenames)\n",
    "\n",
    "        numpy_targets = targets.numpy()\n",
    "        target_list.append(numpy_targets)\n",
    "\n",
    "        outputs = numpy_targets\n",
    "        images = images.to(device)\n",
    "\n",
    "        # NOTE: VitWrapper automatically returns results of last for blocks\n",
    "        outputs = model(images)\n",
    "\n",
    "        # numpy_outputs = None\n",
    "        # if \"BaseModelOutputWithPooling\" in str(type(outputs)):\n",
    "        #     preferred_shape = [numpy_targets.shape[0], -1] # Shape must be 2D\n",
    "        #     numpy_outputs = outputs.last_hidden_state.cpu().numpy().reshape(preferred_shape)\n",
    "        # else:\n",
    "        numpy_outputs = outputs.cpu().numpy()\n",
    "        features_list.append(numpy_outputs)\n",
    "\n",
    "    print(f\"Number of batches: {len(target_list)}\")\n",
    "    np_features = np.concatenate(features_list)\n",
    "    np_target = np.concatenate(target_list)  # .reshape((np_features.shape[0], 1))\n",
    "    df_full = pd.DataFrame(np_features)\n",
    "    df_full[\"target_num\"] = pd.Series(np_target)\n",
    "    df_full[\"filename\"] = pd.Series(filename_list)\n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save_dataframe(df_features, csv_path):\n",
    "    df_split = pd.read_csv(os.path.join(dataset_path, \"split.csv\"), index_col=0)\n",
    "    assert (\n",
    "        df_split[\"target_code\"].unique().size == df_features[\"target_num\"].unique().size\n",
    "    )\n",
    "    assert df_split[\"filename\"].unique().size == df_features[\"filename\"].unique().size\n",
    "    df_split[\"filename\"] = df_split[\"filename\"].apply(lambda x: os.path.splitext(x)[0])\n",
    "    df_features[\"filename\"] = df_features[\"filename\"].apply(\n",
    "        lambda x: os.path.splitext(x)[0]\n",
    "    )\n",
    "    df_merged = pd.merge(df_features, df_split, on=\"filename\")\n",
    "    groups = df_merged.groupby([\"target_code\", \"target_num\"])\n",
    "    assert groups[\"set\"].count().size == df_split[\"target_code\"].unique().size\n",
    "\n",
    "    df_merged.drop(columns=[\"filename\", \"target_code\"], inplace=True)\n",
    "    cols = df_merged.columns.tolist()\n",
    "    cols = cols[-2:] + cols[:-2]\n",
    "    df_merged = df_merged[cols]\n",
    "    df_merged.to_csv(csv_path)\n",
    "    print(f\"Csv file saved: {feature_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Csv file already exists: ../datasets/intermediate-features/PAD_UFES_20-ViT_T16-Derma.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/PAD_UFES_20-ViT_T16-ImageNet_1k_SL_WinKawaks.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/PAD_UFES_20-ViT_T16-ImageNet_1k_SSL_Dino.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/PAD_UFES_20-ViT_T16-ImageNet_AugReg.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/PAD_UFES_20-ViT_T16-Plant.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/PAD_UFES_20-ViT_T16-Random.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/DDI-ViT_T16-Derma.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/DDI-ViT_T16-ImageNet_1k_SL_WinKawaks.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/DDI-ViT_T16-ImageNet_1k_SSL_Dino.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/DDI-ViT_T16-ImageNet_AugReg.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/DDI-ViT_T16-Plant.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/DDI-ViT_T16-Random.csv\n",
      "Csv file already exists: ../datasets/intermediate-features/HAM10000-ViT_T16-Derma.csv\n",
      "Skipped 13 existing files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../model_weights/vit_t16_v1/ViT_T16-ImageNet_1k_SL_WinKawaks_headless.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\thesis\\.venv\\lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:253: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  context_layer = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 721\n",
      "Csv file saved: ../datasets/intermediate-features/HAM10000-ViT_T16-ImageNet_1k_SL_WinKawaks.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-ImageNet_1k_SSL_Dino_headless.pth\n",
      "Number of batches: 721\n",
      "Csv file saved: ../datasets/intermediate-features/HAM10000-ViT_T16-ImageNet_1k_SSL_Dino.csv\n",
      "Loading ../model_weights/vit_t16_v3/ViT_T16-ImageNet_AugReg_headless.pth\n",
      "Number of batches: 721\n",
      "Csv file saved: ../datasets/intermediate-features/HAM10000-ViT_T16-ImageNet_AugReg.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-Plant_SSL_Dino_headless.pth\n",
      "Number of batches: 721\n",
      "Csv file saved: ../datasets/intermediate-features/HAM10000-ViT_T16-Plant.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-Random_headless.pth\n",
      "Number of batches: 721\n",
      "Csv file saved: ../datasets/intermediate-features/HAM10000-ViT_T16-Random.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-Derma_SSL_Dino_headless.pth\n",
      "Number of batches: 1037\n",
      "Csv file saved: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-Derma.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../model_weights/vit_t16_v1/ViT_T16-ImageNet_1k_SL_WinKawaks_headless.pth\n",
      "Number of batches: 1037\n",
      "Csv file saved: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-ImageNet_1k_SL_WinKawaks.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-ImageNet_1k_SSL_Dino_headless.pth\n",
      "Number of batches: 1037\n",
      "Csv file saved: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-ImageNet_1k_SSL_Dino.csv\n",
      "Loading ../model_weights/vit_t16_v3/ViT_T16-ImageNet_AugReg_headless.pth\n",
      "Number of batches: 1037\n",
      "Csv file saved: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-ImageNet_AugReg.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-Plant_SSL_Dino_headless.pth\n",
      "Number of batches: 1037\n",
      "Csv file saved: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-Plant.csv\n",
      "Loading ../model_weights/vit_t16_v2/ViT_T16-Random_headless.pth\n",
      "Number of batches: 1037\n",
      "Csv file saved: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-Random.csv\n"
     ]
    }
   ],
   "source": [
    "df_config = pd.read_csv(configuration_csv_path)\n",
    "counter = 0\n",
    "\n",
    "df_config\n",
    "\n",
    "for index, row in df_config.iterrows():\n",
    "    dataset_path = str(row[\"dataset_path\"])\n",
    "    architecture = str(row[\"architecture\"])\n",
    "    weigths_path = str(row[\"weigths_path\"])\n",
    "    feature_path = str(row[\"feature_path\"])\n",
    "\n",
    "    target_filename = os.path.basename(feature_path)\n",
    "    name_parts = target_filename.split(\".\")\n",
    "    assert len(name_parts) == 2\n",
    "    assert name_parts[1] == \"csv\"\n",
    "    name_parts = name_parts[0].split(\"-\")\n",
    "    assert len(name_parts) == 3\n",
    "    assert name_parts[0].lower() in dataset_path.replace(\"-\", \"_\").lower()\n",
    "    assert name_parts[1] == architecture\n",
    "    assert name_parts[2] in weigths_path\n",
    "\n",
    "    if os.path.exists(feature_path):\n",
    "        print(f\"Csv file already exists: {feature_path}\")\n",
    "        counter += 1\n",
    "    else:\n",
    "        if 0 < counter:\n",
    "            print(f\"Skipped {counter} existing files\")\n",
    "            counter = 0\n",
    "        model = load_model(architecture, weigths_path)\n",
    "        dataloader = load_dataloader(dataset_path)\n",
    "        df_features = calculate_features(model, dataloader)\n",
    "        split_and_save_dataframe(df_features, feature_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412f64844b7b8af74bdbb265a073648c443bf75ef51a1e949163ab9198702ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
