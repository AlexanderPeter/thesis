{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from local_python.feature_evaluation import (\n",
    "    evaluate_with_knn, evaluate_with_lr, calculate_scores\n",
    ")\n",
    "from local_python.general_utils import (\n",
    "    set_seed,\n",
    "    load_pd_from_json,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_source_directory = \"../datasets/intermediate-features/\"\n",
    "metric_target_directory = \"../runs/\"\n",
    "master_file_name = \"master-metrics-remaining.txt\"\n",
    "# previous_file_name = \"master-metrics-vit-derma.txt\"\n",
    "# previous_file_name = \"master-metrics-vit-plant.txt\"\n",
    "# previous_file_name = \"master-metrics-resnet-derma.txt\"\n",
    "# previous_file_name = \"master-metrics-resnet-plant.txt\"\n",
    "previous_file_name = \"empty.txt\"\n",
    "\n",
    "seed_list = range(100)\n",
    "max_neighbors = 200\n",
    "max_iter = 10_000\n",
    "knn_metric = \"cosine\"\n",
    "\n",
    "detail_selection_config = {  # number of samples and seeds\n",
    "    1: seed_list,\n",
    "    3: seed_list,\n",
    "    10: seed_list,\n",
    "    30: seed_list,\n",
    "    100: seed_list,\n",
    "    None: [None],\n",
    "}\n",
    "\n",
    "master_selection_config = {\n",
    "    None: range(10),\n",
    "}\n",
    "\n",
    "dataset_prefixes = [\n",
    "    \"DDI-ViT_T16-student\",\n",
    "    # \"PAD_UFES_20-ViT_T16-student\",\n",
    "    # \"HAM10000-ViT_T16-student\",\n",
    "    # \"Fitzpatrick17k-ViT_T16-student\",\n",
    "    # \"PlantDoc-ViT_T16-student\",\n",
    "    # \"PlantDataset-ViT_T16-student\",\n",
    "    # \"Cassava-ViT_T16-student\",\n",
    "    # \"PlantVillage-ViT_T16-student\",\n",
    "\n",
    "    \"DDI-ResNet50\",\n",
    "    # \"PAD_UFES_20-ResNet50\",\n",
    "    # \"HAM10000-ResNet50\",\n",
    "    # \"Fitzpatrick17k-ResNet50\",\n",
    "    # \"PlantDoc-ResNet50\",\n",
    "    # \"PlantDataset-ResNet50\",\n",
    "    # \"Cassava-ResNet50\",\n",
    "    # \"PlantVillage-ResNet50\",\n",
    "\n",
    "    # \"DDI-ViT_T16-teacher\",\n",
    "    # \"PAD_UFES_20-ViT_T16-teacher\",\n",
    "    # \"HAM10000-ViT_T16-teacher\",\n",
    "    # \"Fitzpatrick17k-ViT_T16-teacher\",\n",
    "    # \"PlantDoc-ViT_T16-teacher\",\n",
    "    # \"PlantDataset-ViT_T16-teacher\",\n",
    "    # \"Cassava-ViT_T16-teacher\",\n",
    "    # \"PlantVillage-ViT_T16-teacher\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1 entries from empty.txt\n"
     ]
    }
   ],
   "source": [
    "df_previous = load_pd_from_json(os.path.join(metric_target_directory, previous_file_name)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores_of_dataframe(\n",
    "    df_full, number_of_samples, selection_seed, csv_path, evaluations\n",
    "):\n",
    "    df_training = df_full[df_full[\"set\"] == \"train\"]\n",
    "    df_devel = df_full[(df_full[\"set\"] == \"train\") | (df_full[\"set\"] == \"valid\")]\n",
    "    df_train, df_valid = train_test_split(\n",
    "        df_devel, train_size=len(df_training), stratify=df_devel[\"target_code\"], random_state=selection_seed\n",
    "    )\n",
    "    df_test = df_full[df_full[\"set\"] == \"test\"]\n",
    "    if number_of_samples is not None:\n",
    "        target_group = df_train.groupby(\"target_code\")\n",
    "        max_samples_possible = target_group[\"set\"].count().min()\n",
    "        if max_samples_possible < number_of_samples:\n",
    "            # abort because this is impossible\n",
    "            return\n",
    "        df_train = target_group.sample(\n",
    "            number_of_samples, random_state=selection_seed, replace=False\n",
    "        )\n",
    "    features = (\n",
    "        df_train.loc[:, ~df_train.columns.isin([\"target_code\", \"set\"])],\n",
    "        df_valid.loc[:, ~df_valid.columns.isin([\"target_code\", \"set\"])],\n",
    "        df_test.loc[:, ~df_test.columns.isin([\"target_code\", \"set\"])],\n",
    "    )\n",
    "    targets = (\n",
    "        df_train[\"target_code\"].to_numpy(),\n",
    "        df_valid[\"target_code\"].to_numpy(),\n",
    "        df_test[\"target_code\"].to_numpy(),\n",
    "    )\n",
    "\n",
    "    best_k_f1_score_average = \"macro\" if 2 < len(df_full[\"target_code\"].unique()) else \"binary\"\n",
    "    entries = []\n",
    "    for evaluation in evaluations:\n",
    "        entry = {}\n",
    "        entry[\"feature_identifier\"] = csv_path\n",
    "        entry[\"selection_seed\"] = selection_seed\n",
    "        entry[\"number_of_samples\"] = number_of_samples\n",
    "        entry[\"model_name\"] = evaluation\n",
    "\n",
    "        if evaluation == \"lr\":\n",
    "            entry = evaluate_with_lr(\n",
    "                features,\n",
    "                targets,\n",
    "                entry,\n",
    "                seed=selection_seed,\n",
    "                max_iter=max_iter,\n",
    "            )\n",
    "        elif evaluation == \"knn\":\n",
    "            entry = evaluate_with_knn(\n",
    "                features,\n",
    "                targets,\n",
    "                entry,\n",
    "                number_of_samples,\n",
    "                knn_metric=knn_metric,\n",
    "                max_neighbors=max_neighbors,\n",
    "                best_k_f1_score_average=best_k_f1_score_average,\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Unknown evaluation method {evaluation}\")\n",
    "        entries.append(entry)\n",
    "    return entries\n",
    "\n",
    "def calculate_scores_of_file(csv_path, metric_file_path, sample_selection_config):\n",
    "    evaluations = [\"lr\", \"knn\"]\n",
    "    df_full = None\n",
    "    for number_of_samples in sample_selection_config:\n",
    "        selection_seeds = sample_selection_config[number_of_samples]\n",
    "        number_of_existing_entries = sum((df_previous[\"feature_identifier\"]==csv_path) & (df_previous[\"number_of_samples\"]==str(number_of_samples)))\n",
    "        if len(selection_seeds) * len(evaluations) <= number_of_existing_entries:\n",
    "            continue\n",
    "        if df_full is None:\n",
    "            print(f\"- Processing: {csv_file}\")\n",
    "            df_full = pd.read_csv(csv_path, index_col=0)\n",
    "        for selection_seed in tqdm(selection_seeds):\n",
    "            set_seed(selection_seed, verbose=False)\n",
    "            entries = calculate_scores_of_dataframe(\n",
    "                df_full, number_of_samples, selection_seed, csv_path, evaluations\n",
    "            )\n",
    "            with open(metric_file_path, \"a\") as detaillog:\n",
    "                for entry in entries:\n",
    "                    json.dump(entry, detaillog, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warn: No source file with prefix 'DDI-ViT_T16-student' found\n",
      "'DDI-ResNet50' has 5 source files and 1 target files\n",
      "Source files 112\n",
      "Target files 40\n"
     ]
    }
   ],
   "source": [
    "csv_files = set(os.listdir(path=csv_source_directory))\n",
    "metric_files = set(os.listdir(path=metric_target_directory))\n",
    "\n",
    "# configuration check\n",
    "covered_csv_files = set()\n",
    "covered_metric_files = set()\n",
    "\n",
    "for dataset_prefix in dataset_prefixes:\n",
    "    matches_source = [x for x in csv_files if x.startswith(dataset_prefix)]\n",
    "    if 0 == len(matches_source):\n",
    "        print(f\"Warn: No source file with prefix '{dataset_prefix}' found\")\n",
    "        continue\n",
    "    else:\n",
    "        covered_csv_files.update(matches_source)\n",
    "\n",
    "    matches_target = [x for x in metric_files if x.startswith(dataset_prefix)]\n",
    "    if 1 < len(matches_target):\n",
    "        print(\n",
    "            f\"Warn: {len(matches_target)} target files found with prefix '{dataset_prefix}'\"\n",
    "        )\n",
    "        print(matches_target)\n",
    "\n",
    "    print(\n",
    "        f\"'{dataset_prefix}' has {len(matches_source)} source files and {len(matches_target)} target files\"\n",
    "    )\n",
    "    covered_metric_files.update(matches_target)\n",
    "\n",
    "\n",
    "print(f\"Source files {len(csv_files)}\")\n",
    "print(f\"Target files {len(metric_files)}\")\n",
    "# uncovered_csv_files = csv_files - covered_csv_files\n",
    "# uncovered_metric_files = metric_files - covered_metric_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating 'DDI-ViT_T16' to '../runs/master-metrics-remaining.txt'\n",
      "- Processing: DDI-ViT_T16-Random.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n",
      "binary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m csv_file\u001b[38;5;241m.\u001b[39mstartswith(dataset_prefix):\n\u001b[0;32m     14\u001b[0m     csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_source_directory, csv_file)\n\u001b[1;32m---> 15\u001b[0m     \u001b[43mcalculate_scores_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_selection_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 82\u001b[0m, in \u001b[0;36mcalculate_scores_of_file\u001b[1;34m(csv_path, metric_file_path, sample_selection_config)\u001b[0m\n\u001b[0;32m     78\u001b[0m entries \u001b[38;5;241m=\u001b[39m calculate_scores_of_dataframe(\n\u001b[0;32m     79\u001b[0m     df_full, number_of_samples, selection_seed, csv_path, evaluations\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(metric_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m detaillog:\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m entries:\n\u001b[0;32m     83\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(entry, detaillog, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "metric_file_path = os.path.join(metric_target_directory, master_file_name)\n",
    "if not os.path.exists(metric_file_path):\n",
    "    for dataset_prefix in dataset_prefixes: # [:1]\n",
    "        if \"-teacher\" in dataset_prefix:\n",
    "            continue\n",
    "        dataset_prefix = dataset_prefix.replace(\n",
    "            \"-student\", \"\"\n",
    "        )\n",
    "        print(f\"Calculating '{dataset_prefix}' to '{metric_file_path}'\")\n",
    "        for i, csv_file in enumerate(csv_files):\n",
    "            if \"-teacher\" in csv_file:\n",
    "                continue\n",
    "            if csv_file.startswith(dataset_prefix):\n",
    "                csv_path = os.path.join(csv_source_directory, csv_file)\n",
    "                calculate_scores_of_file(csv_path, metric_file_path, master_selection_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric file already exists: ../runs/PlantDoc-ViT_T16-student-metrics.txt\n",
      "Metric file already exists: ../runs/PlantDataset-ViT_T16-student-metrics.txt\n",
      "Metric file already exists: ../runs/Cassava-ViT_T16-student-metrics.txt\n",
      "Metric file already exists: ../runs/PlantVillage-ViT_T16-student-metrics.txt\n"
     ]
    }
   ],
   "source": [
    "for dataset_prefix in dataset_prefixes:\n",
    "    metric_file_path = os.path.join(\n",
    "        metric_target_directory, f\"{dataset_prefix}-metrics.txt\"\n",
    "    )\n",
    "    if os.path.exists(metric_file_path):\n",
    "        print(f\"Metric file already exists: {metric_file_path}\")\n",
    "        continue\n",
    "\n",
    "    dataset_prefix = dataset_prefix.replace(\"-student\", \"\")  # NOTE: dirty workaround\n",
    "    print(f\"Calculating '{dataset_prefix}' to '{metric_file_path}'\")\n",
    "    for i, csv_file in enumerate(csv_files):\n",
    "        if (\"teacher\" in csv_file) and (\n",
    "            \"teacher\" not in dataset_prefix\n",
    "        ):  # NOTE: dirty workaround\n",
    "            continue\n",
    "        if csv_file.startswith(dataset_prefix):\n",
    "            csv_path = os.path.join(csv_source_directory, csv_file)\n",
    "            calculate_scores_of_file(csv_path, metric_file_path, detail_selection_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412f64844b7b8af74bdbb265a073648c443bf75ef51a1e949163ab9198702ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
