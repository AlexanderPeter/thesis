{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_root_path = \"../datasets/intermediate-features/\"\n",
    "seed_list = range(100)\n",
    "max_neighbors = 200\n",
    "\n",
    "sample_selection_config = {  # number of samples and seeds\n",
    "    1: seed_list,\n",
    "    3: seed_list,\n",
    "    10: seed_list,\n",
    "    30: seed_list,\n",
    "    100: seed_list,\n",
    "    None: [None],\n",
    "}\n",
    "\n",
    "best_k_f1_score_average = \"macro\"  # \"weighted\"\n",
    "knn_metric = \"cosine\"\n",
    "\n",
    "dataset_prefixes = [\n",
    "    # \"Cassava_Mini-\", \n",
    "    \"DDI-\",\n",
    "    \"PAD_UFES_20-\",\n",
    "    \"HAM10000-\",\n",
    "    \"Fitzpatrick17k-\",\n",
    "    # \"PlantDoc-\", \n",
    "    # \"PlantDataset-\",\n",
    "    # \"Cassava-\", \n",
    "    # \"PlantVillage-\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(\n",
    "    targets,\n",
    "    predictions,\n",
    "    model_name=None,\n",
    "    feature_identifier=None,\n",
    "    number_of_samples=None,\n",
    "    selection_seed=None,\n",
    "    metric_file_path=None,\n",
    "    best_k=None,\n",
    "):\n",
    "    accuracy = accuracy_score(targets, predictions)\n",
    "    balanced_accuracy = balanced_accuracy_score(targets, predictions)\n",
    "    f1_weighted = f1_score(targets, predictions, average=\"weighted\")\n",
    "    f1_micro = f1_score(targets, predictions, average=\"micro\")\n",
    "    f1_macro = f1_score(targets, predictions, average=\"macro\")\n",
    "    if model_name is None or feature_identifier is None:\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "        print(f\"Balanced accuracy: {balanced_accuracy}\")\n",
    "        print(f\"F1-weighted: {f1_weighted}\")\n",
    "        print(f\"F1-micro: {f1_micro}\")\n",
    "        print(f\"F1-macro: {f1_macro}\")\n",
    "    else:\n",
    "        # print(f\"model_name={model_name}, feature_identifier={feature_identifier}\")\n",
    "        # print(f\"model_name={model_name}\")\n",
    "        # print(f\"model_name={model_name}, number_of_samples={number_of_samples}, selection_seed={selection_seed}\")\n",
    "        with open(metric_file_path, \"a\") as detaillog:\n",
    "            entry = {}\n",
    "            entry[\"model_name\"] = model_name\n",
    "            entry[\"feature_identifier\"] = feature_identifier\n",
    "            entry[\"number_of_samples\"] = number_of_samples\n",
    "            entry[\"selection_seed\"] = selection_seed\n",
    "            entry[\"accuracy\"] = accuracy\n",
    "            entry[\"balanced_accuracy\"] = balanced_accuracy\n",
    "            entry[\"f1_weighted\"] = f1_weighted\n",
    "            entry[\"f1_micro\"] = f1_micro\n",
    "            entry[\"f1_macro\"] = f1_macro\n",
    "            entry[\"best_k\"] = best_k\n",
    "            json.dump(entry, detaillog, indent=2)\n",
    "\n",
    "\n",
    "def calculate_scores_of_file(csv_path, metric_file_path):\n",
    "    print(f\"loading: {csv_path}\")\n",
    "    df_full = pd.read_csv(csv_path, index_col=0)\n",
    "    for number_of_samples in sample_selection_config:\n",
    "        print(f\"number_of_samples: {number_of_samples}\")\n",
    "        selection_seeds = sample_selection_config[number_of_samples]\n",
    "        for selection_seed in selection_seeds:\n",
    "            calculate_scores_of_dataframe(\n",
    "                df_full, number_of_samples, selection_seed, metric_file_path\n",
    "            )\n",
    "\n",
    "\n",
    "def calculate_scores_of_dataframe(\n",
    "    df_full, number_of_samples, selection_seed, metric_file_path\n",
    "):\n",
    "    # print(f\"number_of_samples={number_of_samples}, selection_seed={selection_seed}\")\n",
    "    df_train = df_full[df_full[\"set\"] == \"train\"]\n",
    "    df_valid = df_full[df_full[\"set\"] == \"valid\"]\n",
    "    df_test = df_full[df_full[\"set\"] == \"test\"]\n",
    "    if number_of_samples is not None:\n",
    "        target_group = df_train.groupby(\"target_num\")\n",
    "        max_samples_possible = target_group[\"set\"].count().min()\n",
    "        if max_samples_possible < number_of_samples:\n",
    "            # abort because this is impossible\n",
    "            return\n",
    "\n",
    "        df_train = target_group.sample(\n",
    "            number_of_samples, random_state=selection_seed, replace=False\n",
    "        )\n",
    "\n",
    "    train_features = df_train.loc[:, ~df_train.columns.isin([\"target_num\", \"set\"])]\n",
    "    valid_features = df_valid.loc[:, ~df_valid.columns.isin([\"target_num\", \"set\"])]\n",
    "    test_features = df_test.loc[:, ~df_test.columns.isin([\"target_num\", \"set\"])]\n",
    "\n",
    "    train_targets = df_train[\"target_num\"].to_numpy()\n",
    "    valid_targets = df_valid[\"target_num\"].to_numpy()\n",
    "    test_targets = df_test[\"target_num\"].to_numpy()\n",
    "\n",
    "    model_lr = LogisticRegression(max_iter=10_000)\n",
    "    model_lr.fit(train_features, train_targets)\n",
    "\n",
    "    valid_pred = model_lr.predict(valid_features)\n",
    "    test_pred = model_lr.predict(test_features)\n",
    "    calculate_scores(\n",
    "        test_targets,\n",
    "        test_pred,\n",
    "        \"lr\",\n",
    "        csv_path,\n",
    "        number_of_samples,\n",
    "        selection_seed,\n",
    "        metric_file_path,\n",
    "    )\n",
    "\n",
    "    scores = {}\n",
    "    neighbors_limit = max_neighbors\n",
    "    if number_of_samples is not None:\n",
    "        neighbors_limit = min(neighbors_limit, 1 + number_of_samples)\n",
    "\n",
    "    for k in range(1, neighbors_limit):\n",
    "        model_knn = KNeighborsClassifier(n_neighbors=k,  metric=knn_metric)\n",
    "        model_knn.fit(train_features, train_targets)\n",
    "        valid_pred = model_knn.predict(valid_features)\n",
    "        score = f1_score(valid_targets, valid_pred, average=best_k_f1_score_average)\n",
    "        scores[k] = score\n",
    "    # print(f\"Scores {scores}\")\n",
    "\n",
    "    best_k = max(scores, key=scores.get)\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    model_knn.fit(train_features, train_targets)\n",
    "    test_pred = model_knn.predict(test_features)\n",
    "    calculate_scores(\n",
    "        test_targets,\n",
    "        test_pred,\n",
    "        \"knn\",\n",
    "        csv_path,\n",
    "        number_of_samples,\n",
    "        selection_seed,\n",
    "        metric_file_path,\n",
    "        best_k=best_k,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_paths = os.listdir(path=csv_root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DDI-\n",
      "Metric file already exists: ../runs/DDI-ViT_T16-metrics.txt\n",
      "Processing PAD_UFES_20-\n",
      "Metric file already exists: ../runs/PAD_UFES_20-ViT_T16-metrics.txt\n",
      "Processing HAM10000-\n",
      "loading: ../datasets/intermediate-features/HAM10000-ViT_T16-Derma.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/HAM10000-ViT_T16-ImageNet_1k_SL_WinKawaks.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/HAM10000-ViT_T16-ImageNet_1k_SSL_Dino.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/HAM10000-ViT_T16-ImageNet_AugReg.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\thesis\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ../datasets/intermediate-features/HAM10000-ViT_T16-Plant.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\thesis\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ../datasets/intermediate-features/HAM10000-ViT_T16-Random.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "Processing Fitzpatrick17k-\n",
      "loading: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-Derma.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-ImageNet_1k_SL_WinKawaks.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-ImageNet_1k_SSL_Dino.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-ImageNet_AugReg.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\workspace\\thesis\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-Plant.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n",
      "loading: ../datasets/intermediate-features/Fitzpatrick17k-ViT_T16-Random.csv\n",
      "number_of_samples: 1\n",
      "number_of_samples: 3\n",
      "number_of_samples: 10\n",
      "number_of_samples: 30\n",
      "number_of_samples: 100\n",
      "number_of_samples: None\n"
     ]
    }
   ],
   "source": [
    "for dataset_prefix in dataset_prefixes:\n",
    "    print(f\"Processing {dataset_prefix}\")\n",
    "    metric_file_path = f\"../runs/{dataset_prefix}ViT_T16-metrics.txt\"\n",
    "    if os.path.exists(metric_file_path):\n",
    "        print(f\"Metric file already exists: {metric_file_path}\")\n",
    "        continue\n",
    "    for i, path in enumerate(csv_paths):\n",
    "        if path.startswith(dataset_prefix):\n",
    "            csv_path = os.path.join(csv_root_path, path)\n",
    "            calculate_scores_of_file(csv_path, metric_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412f64844b7b8af74bdbb265a073648c443bf75ef51a1e949163ab9198702ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
