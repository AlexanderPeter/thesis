{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "from tqdm import tqdm\n",
    "from timm.models.vision_transformer import VisionTransformer\n",
    "\n",
    "from local_python.general_utils import (\n",
    "    load_model,\n",
    "    load_pd_from_json,\n",
    "    load_values_from_previous_epochs,\n",
    "    print_parameters,\n",
    "    set_seed,\n",
    ")\n",
    "from local_python.dataset_util import (\n",
    "    create_dataloaders,\n",
    ")\n",
    "\n",
    "from lora_vit.models import LoRA_ViT_timm\n",
    "from ssl_library.src.models.fine_tuning.classifiers import LinearClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_csv_path = \"./configs/finetune-configuration.csv\"\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>strategy</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>checkpoint_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>lora_2</td>\n",
       "      <td>../data_splits/HAM10000_split.csv</td>\n",
       "      <td>../model_weights/vit_t16_v2/ViT_T16-ImageNet_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lora_4</td>\n",
       "      <td>../data_splits/HAM10000_split.csv</td>\n",
       "      <td>../model_weights/vit_t16_v2/ViT_T16-ImageNet_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seed strategy                       dataset_path  \\\n",
       "0     1   lora_2  ../data_splits/HAM10000_split.csv   \n",
       "1     1   lora_4  ../data_splits/HAM10000_split.csv   \n",
       "\n",
       "                                     checkpoint_path  \n",
       "0  ../model_weights/vit_t16_v2/ViT_T16-ImageNet_1...  \n",
       "1  ../model_weights/vit_t16_v2/ViT_T16-ImageNet_1...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_config = pd.read_csv(configuration_csv_path)\n",
    "df_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(checkpoint_path, strategy, num_classes, image_shape):\n",
    "    strategy_params = strategy.split(\"_\")\n",
    "\n",
    "    if \"concat\" == strategy_params[0]:\n",
    "        rank = int(strategy_params[1])\n",
    "        model = load_model(checkpoint_path, freeze=False, use_ssl_library=True)\n",
    "        params = list(model.parameters())\n",
    "        for param in params[: len(params) - rank]:\n",
    "            param.requires_grad = False\n",
    "        summary = torchinfo.summary(model, image_shape, batch_dim=0)\n",
    "        last_output = summary.summary_list[-1].output_size[-1]\n",
    "        model.head = LinearClassifier(\n",
    "            last_output,\n",
    "            num_labels=num_classes,\n",
    "            use_dropout_in_head=True,\n",
    "            large_head=False,\n",
    "            use_bn=True,\n",
    "        )\n",
    "    elif \"lora\" == strategy_params[0]:\n",
    "        rank = int(strategy_params[1])\n",
    "        model = load_model(checkpoint_path, freeze=True, use_ssl_library=False)\n",
    "        summary = torchinfo.summary(model, image_shape, batch_dim=0)\n",
    "        last_output = summary.summary_list[-1].output_size[-1]\n",
    "        assert hasattr(model, \"blocks\"), f\"Unknown model type: {type(model)}\"\n",
    "        model.head = LinearClassifier(\n",
    "            last_output,\n",
    "            num_labels=num_classes,\n",
    "            use_dropout_in_head=True,\n",
    "            large_head=False,\n",
    "            use_bn=True,\n",
    "        )\n",
    "        model = LoRA_ViT_timm(vit_model=model, r=rank, alpha=4)\n",
    "    else:\n",
    "        assert False, f\"Unknown strategy: {strategy}\"\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_eval(\n",
    "    model, optimizer, criterion, start_epoch, end_epoch, dataloaders, loss_file_path, best_loss = None\n",
    "):\n",
    "    model = model.to(device)\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        model.train()\n",
    "        print(f\"Training epoch {epoch}\")\n",
    "        with open(loss_file_path, \"a\") as detaillog:\n",
    "            for i, (images, targets) in enumerate(tqdm(dataloaders[\"train\"])):\n",
    "                images = images.to(device)\n",
    "                targets = torch.as_tensor(targets).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "                line = {}\n",
    "                line[\"epoch\"] = epoch\n",
    "                line[\"iteration\"] = i\n",
    "                line[\"loss\"] = loss.item()\n",
    "                line[\"set\"] = \"train\"\n",
    "                json.dump(line, detaillog, indent=2)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(run_path, f\"checkpoint_latest.pth\"),\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = []\n",
    "        with torch.no_grad():\n",
    "            with open(loss_file_path, \"a\") as detaillog:\n",
    "                for i, (images, targets) in enumerate(tqdm(dataloaders[\"valid\"])):\n",
    "                    images = images.to(device)\n",
    "                    targets = torch.as_tensor(targets).to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    valid_loss.append(loss.item())\n",
    "\n",
    "                    line = {}\n",
    "                    line[\"epoch\"] = epoch\n",
    "                    line[\"iteration\"] = i\n",
    "                    line[\"loss\"] = valid_loss[-1]\n",
    "                    line[\"set\"] = \"valid\"\n",
    "                    json.dump(line, detaillog, indent=2)\n",
    "        \n",
    "        mean_loss = np.array(valid_loss).mean()\n",
    "        if best_loss is None or mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(run_path, f\"checkpoint_best.pth\"),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 960\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()\n",
    "n_devices = torch.cuda.device_count()\n",
    "for i in range(0, n_devices):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed to 1\n",
      "Results will be saved to ../runs/HAM10000\\ViT_T16-ImageNet_1k_SSL_Dino\\lora_2_1\n",
      "Set train size: 8908\n",
      "Set valid size: 1103\n",
      "Train class (im)balance: {'bkl': 971, 'nv': 5969, 'df': 103, 'mel': 992, 'vasc': 128, 'bcc': 455, 'akiec': 290}\n",
      "Loading vit_tiny_patch16_224 from timm-library\n",
      "Ignoring prefix 'model.'\n",
      "Trainable parameters: 18432/5544583\n",
      "Read 19171 entries from loss.txt\n",
      "Latest epoch: 62\n",
      "Best epoch: 61 with 1.2361385055950709\n",
      "Training epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:59<00:00,  2.33it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:00<00:00,  2.32it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:59<00:00,  2.34it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:01<00:00,  2.29it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:02<00:00,  2.28it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:59<00:00,  2.33it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:00<00:00,  2.31it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:03<00:00,  2.27it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.39it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:58<00:00,  2.36it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:59<00:00,  2.33it/s]\n",
      "100%|██████████| 35/35 [00:16<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:06<00:00,  2.20it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.40it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.41it/s]\n",
      "100%|██████████| 35/35 [00:18<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:03<00:00,  2.25it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:06<00:00,  2.21it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:03<00:00,  2.26it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:13<00:00,  2.09it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:09<00:00,  2.16it/s]\n",
      "100%|██████████| 35/35 [00:17<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:04<00:00,  2.25it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:02<00:00,  2.28it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.40it/s]\n",
      "100%|██████████| 35/35 [00:16<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:58<00:00,  2.35it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:06<00:00,  2.21it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:03<00:00,  2.26it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:05<00:00,  2.23it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:03<00:00,  2.26it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.43it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.41it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting seed to 1\n",
      "Results will be saved to ../runs/HAM10000\\ViT_T16-ImageNet_1k_SSL_Dino\\lora_4_1\n",
      "Set train size: 8908\n",
      "Set valid size: 1103\n",
      "Train class (im)balance: {'bkl': 971, 'nv': 5969, 'df': 103, 'mel': 992, 'vasc': 128, 'bcc': 455, 'akiec': 290}\n",
      "Loading vit_tiny_patch16_224 from timm-library\n",
      "Ignoring prefix 'model.'\n",
      "Trainable parameters: 36864/5563015\n",
      "Read 18840 entries from loss.txt\n",
      "Latest epoch: 59\n",
      "Best epoch: 57 with 1.1211333206721714\n",
      "Training epoch 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:57<00:00,  2.38it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:58<00:00,  2.36it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:02<00:00,  2.28it/s]\n",
      "100%|██████████| 35/35 [00:18<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.41it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.41it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.40it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:54<00:00,  2.43it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:54<00:00,  2.43it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:53<00:00,  2.47it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:02<00:00,  2.28it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:57<00:00,  2.37it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [02:00<00:00,  2.31it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:57<00:00,  2.37it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.40it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.39it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:53<00:00,  2.47it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:54<00:00,  2.43it/s]\n",
      "100%|██████████| 35/35 [00:14<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:54<00:00,  2.45it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:53<00:00,  2.46it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.40it/s]\n",
      "100%|██████████| 35/35 [00:15<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:56<00:00,  2.39it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.41it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 279/279 [01:55<00:00,  2.42it/s]\n",
      "100%|██████████| 35/35 [00:13<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in df_config.iterrows():\n",
    "    seed = row[\"seed\"]\n",
    "    set_seed(seed)\n",
    "\n",
    "    checkpoint_path = row[\"checkpoint_path\"]\n",
    "    model_name = os.path.splitext(os.path.basename(checkpoint_path))[0].replace(\n",
    "        \"_headless\", \"\"\n",
    "    )\n",
    "\n",
    "    dataset_path = row[\"dataset_path\"]\n",
    "    dataset_name = os.path.splitext(os.path.basename(dataset_path))[0].replace(\n",
    "        \"_split\", \"\"\n",
    "    )\n",
    "\n",
    "    strategy = row[\"strategy\"]\n",
    "\n",
    "    run_path = os.path.join(\"../runs/\", dataset_name, model_name, f\"{strategy}_{seed}\")\n",
    "    if not os.path.exists(run_path):\n",
    "        os.makedirs(run_path)\n",
    "    print(f\"Results will be saved to {run_path}\")\n",
    "    \n",
    "\n",
    "    batch_size = 64\n",
    "    if strategy.startswith(\"lora\"):\n",
    "        batch_size = 32\n",
    "\n",
    "    dataloaders = create_dataloaders(dataset_path, batch_size=batch_size)\n",
    "    train_class_counts = dataloaders[\"train\"].dataset.get_class_counts()\n",
    "    print(f\"Train class (im)balance: {train_class_counts}\")\n",
    "    num_classes = len(train_class_counts)\n",
    "\n",
    "    images, _ = next(iter(dataloaders[\"valid\"]))\n",
    "    image_shape = images.shape[1:]\n",
    "\n",
    "    model = prepare_model(checkpoint_path, strategy, num_classes, image_shape)\n",
    "    print_parameters(model)\n",
    "\n",
    "    class_weights_tensor = torch.tensor(\n",
    "        1.0 / np.array(list(train_class_counts.values())), dtype=torch.float\n",
    "    )\n",
    "    class_weights_tensor = class_weights_tensor.to(device)\n",
    "    loss_function = nn.CrossEntropyLoss(weight=class_weights_tensor, reduction=\"mean\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    (loss_file_path, latest_epoch, best_loss) = load_values_from_previous_epochs(run_path)\n",
    "\n",
    "    checkpoint_path = os.path.join(run_path, f\"checkpoint_latest.pth\")\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "        model.load_state_dict(checkpoint, strict=True)\n",
    "\n",
    "    checkpoint_path = os.path.join(run_path, f\"checkpoint_best.pth\")\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        best_loss = None # reset    \n",
    "\n",
    "    start_epoch = latest_epoch + 1\n",
    "    end_epoch = start_epoch + 30\n",
    "\n",
    "    train_eval(\n",
    "        model,\n",
    "        optimizer,\n",
    "        loss_function,\n",
    "        start_epoch,\n",
    "        end_epoch,\n",
    "        dataloaders,\n",
    "        loss_file_path,\n",
    "        best_loss = best_loss,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412f64844b7b8af74bdbb265a073648c443bf75ef51a1e949163ab9198702ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
