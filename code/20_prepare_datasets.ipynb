{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate, prepare and split datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 19\n",
    "split_ratio_1 = 0.2  # (validation+test) / (train+validation+test)\n",
    "split_ratio_2 = 0.5  # (test) / (validation+test)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# NOTE: More quality issues are explained in: https://github.com/Digital-Dermatology/SelfClean-Revised-Benchmarks\n",
    "\n",
    "csv_paths = [\"../datasets/PAD-UFES-20/metadata.csv\"]\n",
    "images_root_paths = [\"../datasets/PAD-UFES-20/images/\"]\n",
    "target_column = \"diagnostic\"\n",
    "file_column = \"img_id\"\n",
    "group_columns = [\"patient_id\"]  # , \"lesion_id\"\n",
    "\n",
    "csv_paths = [\"../datasets/ddi-diverse-dermatology-images/ddi_metadata.csv\"]\n",
    "images_root_paths = [\"../datasets/ddi-diverse-dermatology-images/\"]\n",
    "target_column = \"malignant\"  # \"disease\"\n",
    "file_column = \"DDI_file\"\n",
    "group_columns = []\n",
    "\n",
    "csv_paths = [\n",
    "    \"../datasets/HAM10000/HAM10000_metadata\",\n",
    "    \"../datasets/HAM10000/ISIC2018_Task3_Test_GroundTruth.csv\",\n",
    "]  # Given test dataset\n",
    "images_root_paths = [\"../datasets/HAM10000/images/\"]\n",
    "target_column = \"dx\"\n",
    "file_column = \"image_id\"\n",
    "group_columns = [\"lesion_id\"]\n",
    "# NOTE: The image 'ISIC_0035068' (known as the 'easter egg') is corrupted and was therefore excluded manually from the test dataset!\n",
    "\n",
    "csv_paths = [\"../datasets/fitzpatrick17k/fitzpatrick17k.csv\"]\n",
    "images_root_paths = [\"../datasets/fitzpatrick17k/images/\"]\n",
    "target_column = \"three_partition_label\"  # \"nine_partition_label\"\n",
    "file_column = \"md5hash\"  # \"url\"\n",
    "group_columns = []\n",
    "\n",
    "csv_paths = []\n",
    "images_root_paths = [\"../datasets/PlantDataset/\"]\n",
    "target_column = None\n",
    "file_column = None\n",
    "group_columns = []\n",
    "\n",
    "csv_paths = []\n",
    "images_root_paths = [\n",
    "    \"../datasets/plantdoc-dataset/train/\",\n",
    "    \"../datasets/plantdoc-dataset/test/\",\n",
    "]\n",
    "target_column = None\n",
    "file_column = None\n",
    "group_columns = []\n",
    "# The following files are originally included in the train and test set and were moved manually to the duplicates subdirectory:\n",
    "# ../datasets/plantdoc-dataset/train/Corn Gray leaf spot/2013Corn_GrayLeafSpot_0815_0003.JPG.jpg\n",
    "# ../datasets/plantdoc-dataset/test/Corn leaf blight/2013Corn_GrayLeafSpot_0815_0003.JPG.jpg\n",
    "# ../datasets/plantdoc-dataset/train/Potato leaf early blight/early-blight-or-target-spot-alternaria-solani-lesions-on-a-tomato-by9j8r.jpg\n",
    "# ../datasets/plantdoc-dataset/train/Tomato Early blight leaf/early-blight-or-target-spot-alternaria-solani-lesions-on-a-tomato-BY9J8R.jpg\n",
    "\n",
    "csv_paths = [\"../datasets/cassava-leaf-disease-classification/train.csv\"]\n",
    "images_root_paths = [\"../datasets/cassava-leaf-disease-classification/train_images/\"]\n",
    "target_column = \"label\"\n",
    "file_column = \"image_id\"\n",
    "group_columns = []\n",
    "\n",
    "csv_paths = []\n",
    "images_root_paths = [\"../datasets/PlantVillage-Dataset/raw/color/\"]\n",
    "target_column = None\n",
    "file_column = None\n",
    "group_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_column is None:\n",
    "    target_column = \".\"\n",
    "    # Use directory structure instead of target column\n",
    "\n",
    "if file_column is None:\n",
    "    file_column = \"filepath\"\n",
    "    # Use default value\n",
    "\n",
    "if 0 == len(csv_paths):\n",
    "    csv_paths = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_duplicates(src_path, duplicates_path):\n",
    "    dst_dir = os.path.join(duplicates_path, os.path.basename(os.path.dirname(src_path)))\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    dst_path = os.path.join(dst_dir, os.path.basename(src_path))\n",
    "    shutil.move(src_path, dst_path)\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "# move_duplicates(\n",
    "#     \"../datasets/plantdoc-dataset/train/Corn Gray leaf spot/2013Corn_GrayLeafSpot_0815_0003.JPG.jpg\",\n",
    "#     \"../datasets/plantdoc-dataset/train/duplicates\",\n",
    "# )\n",
    "# move_duplicates(\n",
    "#     \"../datasets/plantdoc-dataset/test/Corn leaf blight/2013Corn_GrayLeafSpot_0815_0003.JPG.jpg\",\n",
    "#     \"../datasets/plantdoc-dataset/test/duplicates\",\n",
    "# )\n",
    "# move_duplicates(\n",
    "#     \"../datasets/plantdoc-dataset/train/Potato leaf early blight/early-blight-or-target-spot-alternaria-solani-lesions-on-a-tomato-by9j8r.jpg\",\n",
    "#     \"../datasets/plantdoc-dataset/train/duplicates\",\n",
    "# )\n",
    "# move_duplicates(\n",
    "#     \"../datasets/plantdoc-dataset/train/Tomato Early blight leaf/early-blight-or-target-spot-alternaria-solani-lesions-on-a-tomato-BY9J8R.jpg\",\n",
    "#     \"../datasets/plantdoc-dataset/train/duplicates\",\n",
    "# )\n",
    "# move_duplicates(\n",
    "#     \"../datasets/plantdoc-dataset/train/Potato leaf early blight/potato-blight-phytophora-infestans-close-up-of-infected-leaf-top-surface-a60hxg.jpg\",\n",
    "#     \"../datasets/plantdoc-dataset/train/duplicates\",\n",
    "# )\n",
    "# move_duplicates(\n",
    "#     \"../datasets/plantdoc-dataset/train/Potato leaf late blight/potato-blight-phytophora-infestans-close-up-of-infected-leaf-top-surface-A60HXG.jpg\",\n",
    "#     \"../datasets/plantdoc-dataset/train/duplicates\",\n",
    "# )\n",
    "\n",
    "# NOTE: In some cases the file hash is not enough to check...\n",
    "# hashlib.md5(open(\"../datasets/plantdoc-dataset/train/Tomato Early blight leaf/earlyblightpotato.jpg\", \"rb\").read()).hexdigest() # d2c45e81c5de5a2f731829ed491e8df5\n",
    "# hashlib.md5(open(\"../datasets/plantdoc-dataset/test/Potato leaf early blight/earlyblightpotato.jpg\", \"rb\").read()).hexdigest() # be11519577cb929d21a68170b2ec88f1\n",
    "# hashlib.md5(Image.open('../datasets/plantdoc-dataset/test/Potato leaf early blight/earlyblightpotato.jpg', \"r\").tobytes()).hexdigest() # 8fec6255afb5003f62de6989e9b40721\n",
    "# hashlib.md5(Image.open('../datasets/plantdoc-dataset/train/Tomato Early blight leaf/earlyblightpotato.jpg', \"r\").tobytes()).hexdigest() # 8fec6255afb5003f62de6989e9b40721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ../datasets/PlantVillage-Dataset/raw/color/\n",
      "Found 0 files\n",
      "Found 630 files\n",
      "Found 621 files\n",
      "Found 275 files\n",
      "Found 1645 files\n",
      "File with equal hash (dbdc7b5c2c6c935a3bc960a5fdf5ea9c) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\11beda66-01e9-4bfd-be37-c0f8646d1478___RS_HL 6271.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\13298d36-4425-437d-ae8e-c7d70e200084___RS_HL 6271.JPG\n",
      "File with equal hash (1e86760b7721d066126b20056e8d5bb2) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\1ab5e019-e5f0-4d8e-a252-94cb0aab8b0a___RS_HL 6269.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\3673d121-b5de-481c-b057-d4ee5b4959b1___RS_HL 6269.JPG\n",
      "File with equal hash (1987c933d1b47a1ef89727337ffdcc83) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\5192db55-4aa7-421c-92d4-c2dac79e7379___RS_HL 6273.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\9b75de13-d4b0-4b3f-988c-3e9926eef957___RS_HL 6273.JPG\n",
      "File with equal hash (3bf88aaeb7af8b51f2ac7d031515cf8c) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\3d075f90-7002-4c45-abc0-4f35ee49aa79___RS_HL 6272.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\acb21cc2-8d65-4880-a7bb-dcc1eab1564b___RS_HL 6272.JPG\n",
      "File with equal hash (ee77e60900cd786f301cce876c8adbe7) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\14896dc0-688d-456f-b5ec-a037695b0193___RS_HL 6268.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\c21cf428-bfc3-4710-b5d2-69d1c0e94748___RS_HL 6268.JPG\n",
      "File with equal hash (aea634092a92e5d03b25dbd739b636d1) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\ced4e27a-5eff-4190-a33a-cdc3d84c811e___RS_HL 6270.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\dc18b924-f172-445d-8fed-61445d437aaa___RS_HL 6270.JPG\n",
      "File with equal hash (92e4a693d09b3e364a04d659d2986560) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\f2cda910-55c7-46d7-b1a2-9a3bb9792148___RS_HL 6274.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___healthy\\fdbfa6f7-f887-442d-8df1-1f0cf839fc4d___RS_HL 6274.JPG\n",
      "Found 1502 files\n",
      "Found 854 files\n",
      "Found 1052 files\n",
      "Found 513 files\n",
      "Found 1192 files\n",
      "Found 1162 files\n",
      "Found 985 files\n",
      "Skip: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\duplicates\n",
      "Skip: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\duplicates\\Apple___healthy\n",
      "Found 1180 files\n",
      "Found 1383 files\n",
      "Found 423 files\n",
      "Found 1076 files\n",
      "Found 5507 files\n",
      "Found 2297 files\n",
      "Found 360 files\n",
      "Found 997 files\n",
      "Found 1478 files\n",
      "Found 1000 files\n",
      "Found 152 files\n",
      "Found 1000 files\n",
      "Found 371 files\n",
      "Found 5090 files\n",
      "Found 1835 files\n",
      "Found 456 files\n",
      "Found 1109 files\n",
      "Found 2127 files\n",
      "Found 1000 files\n",
      "Found 1591 files\n",
      "File with equal hash (0b29a96c6ddbfa17b804fe09d7b5c5aa) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\068e324c-faf6-40d6-8f83-578907f1cac5___GH_HL Leaf 466.1.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\34c81c57-e1fa-49dd-a49d-34fe8b2385fe___GH_HL Leaf 466.1.JPG\n",
      "File with equal hash (9e404dc05df145050110000f36161053) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\37203047-d8ba-43f7-b31e-d496c41c569c___GH_HL Leaf 389.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\505465db-407b-4e0a-8110-7479dad5261c___GH_HL Leaf 389.JPG\n",
      "File with equal hash (2c3c85292ea59704ec4988e27277a555) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\488feb1c-4b9f-44e7-8aa6-4103a9601f5f___GH_HL Leaf 434.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\a5de43e7-fc2f-4a14-a8e6-c0f2f94c84f1___GH_HL Leaf 434.JPG\n",
      "File with equal hash (96d5b4e69970605ea1ca4f35e5c76a75) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\1af0bfe1-4bcf-4b8b-be66-5d0953eb647e___GH_HL Leaf 482.2.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\cfd491d6-4af5-4728-8f0e-0d330a07174a___GH_HL Leaf 482.2.JPG\n",
      "File with equal hash (ab955759346d40e184bd8ab2da06757a) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\9662364c-aaba-45e3-b907-10792d60578c___GH_HL Leaf 220.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\d2ce7896-6fa4-45e6-96c5-d162da0e3e1c___GH_HL Leaf 220.JPG\n",
      "File with equal hash (b9d5c9617890f80b405aa5418e7d06e9) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\37aad83b-7ff8-4b35-b3ed-fb8e0f54910b___GH_HL Leaf 342.1.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___healthy\\e786ac89-29fe-47e3-b49e-b9a9ee7edd9d___GH_HL Leaf 342.1.JPG\n",
      "Found 1909 files\n",
      "File with equal hash (5e215af59e73be879930cc8c169f276d) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\1a69b38b-c4eb-42c4-9584-bcb14fb8db0c___GHLB2 Leaf 9011.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\2c47b891-3c97-48f1-a2cc-5aa53d3a1148___GHLB2 Leaf 9011.JPG\n",
      "File with equal hash (cec364c3fb60db0650538bf92f89be9b) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\3fae9c64-18f0-4a67-9f97-554248bb1bed___GHLB_PS Leaf 24 Day 16.jpg, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\5de6da85-f8c4-48c4-b463-3e6bd78884cc___GHLB_PS Leaf 24 Day 16.jpg\n",
      "File with equal hash (0ce1c770837fd4cd35cc0b7901da6a57) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\48c55974-9fe9-4f4b-94f7-c8cd127d1e05___GHLB_PS Leaf 23.7 Day 13.jpg, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\bd4f09bd-ee85-4ab1-bce0-8cde3fdd7f1b___GHLB_PS Leaf 23.7 Day 13.jpg\n",
      "File with equal hash (805f77105e015db099ff26a0b6020ba7) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\98586693-fe1f-4ea0-8e27-4501b61cf09b___GHLB_PS Leaf 23.5 Day 13.jpg, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\c1775bad-7c02-41fb-bb7d-f8df91d60ac3___GHLB_PS Leaf 23.5 Day 13.jpg\n",
      "File with equal hash (288508d7883f96452a46745acd3d00d1) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\d6e6897a-5083-4914-9903-804c5684a956___GHLB2 Leaf 102.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\d81682aa-746b-4e07-af2b-52ebb6f4c017___GHLB2 Leaf 102.JPG\n",
      "File with equal hash (2ac26f8eb1c2837693a89564a5946a46) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\861d8b00-57a4-46b0-b51a-09d102dbe119___GHLB_PS Leaf 24 Day 13.jpg, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\d82b634e-9a19-497b-b698-aaf100d622a1___GHLB_PS Leaf 24 Day 13.jpg\n",
      "File with equal hash (687ca23e8504a4f55dc093c6c352e5c4) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\5688ea99-c949-41d0-bbab-9cbf0ffb8bcd___GHLB2 Leaf 8677.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\e20107e7-137f-400e-817f-5dc4c58e5d70___GHLB2 Leaf 8677.JPG\n",
      "File with equal hash (9693ba3885c75b81f9779bb962463217) found: ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\5f21282c-e2ef-4c4a-ace1-b5701fe7effc___GHLB2 Leaf 8999.JPG, ..\\datasets\\PlantVillage-Dataset\\raw\\color\\Tomato___Late_blight\\e5d707cd-077c-43af-bda9-6138e516ff51___GHLB2 Leaf 8999.JPG\n",
      "Found 952 files\n",
      "Found 1771 files\n",
      "Found 1676 files\n",
      "Found 1404 files\n",
      "Found 373 files\n",
      "Found 5357 files\n",
      "Found 42 duplicates\n",
      "Total number of files: 54263\n"
     ]
    }
   ],
   "source": [
    "file_hash_dict = {}\n",
    "duplicates = set()\n",
    "skip_extensions = [\".csv\", \".db\"]\n",
    "\n",
    "\n",
    "def check_root_dir(root_dir):\n",
    "    print(f\"Checking {root_dir}\")\n",
    "    duplicates_path = os.path.normpath(os.path.join(root_dir, \"duplicates/\"))\n",
    "    for sub_path, _, filenames in os.walk(os.path.normpath(root_dir)):\n",
    "        sub_path = os.path.normpath(sub_path)\n",
    "        if duplicates_path in sub_path:\n",
    "            print(f\"Skip: {sub_path}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Found {len(filenames)} files\")\n",
    "        for filename in filenames:\n",
    "            file_extension = os.path.splitext(filename)[1].lower()\n",
    "            if file_extension in skip_extensions:\n",
    "                print(f\"Skip non image file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.normpath(os.path.join(sub_path, filename))\n",
    "            # file_hash = os.path.basename(file_path).lower()\n",
    "            file_hash = hashlib.md5(Image.open(file_path, \"r\").tobytes()).hexdigest()\n",
    "            # file_hash = hashlib.md5(open(file_path, \"rb\").read()).hexdigest()\n",
    "            if file_hash in file_hash_dict:\n",
    "                print(\n",
    "                    f\"File with equal hash ({file_hash}) found: {file_hash_dict[file_hash]}, {file_path}\"\n",
    "                )\n",
    "                move_duplicates(file_path, duplicates_path)\n",
    "                file_hash_dict[file_hash] = move_duplicates(\n",
    "                    file_hash_dict[file_hash], duplicates_path\n",
    "                )\n",
    "            else:\n",
    "                file_hash_dict[file_hash] = file_path\n",
    "\n",
    "    for sub_path, _, filenames in os.walk(os.path.normpath(duplicates_path)):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.normpath(os.path.join(sub_path, filename))\n",
    "            duplicates.add(file_path)\n",
    "\n",
    "\n",
    "for root_dir in images_root_paths:\n",
    "    check_root_dir(root_dir)\n",
    "print(f\"Found {len(duplicates)} duplicates\")\n",
    "\n",
    "existing_file_paths = set(file_hash_dict.values()) - duplicates\n",
    "print(f\"Total number of files: {len(existing_file_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['.', 'filepath']\n",
      "Total number of rows: 54263\n"
     ]
    }
   ],
   "source": [
    "def init_dataframes(csv_file, rootpath):\n",
    "    df_return = None\n",
    "    if csv_file is None:\n",
    "        file_column_values = []\n",
    "        target_column_values = []\n",
    "        target_dirs = [\n",
    "            name\n",
    "            for name in os.listdir(path=rootpath)\n",
    "            if os.path.isdir(os.path.join(rootpath, name))\n",
    "        ]\n",
    "        for target_dir in target_dirs:\n",
    "            image_file_paths = [\n",
    "                os.path.normpath(os.path.join(rootpath, target_dir, name))\n",
    "                for name in os.listdir(path=os.path.join(rootpath, target_dir))\n",
    "                if os.path.isfile(os.path.join(rootpath, target_dir, name))\n",
    "            ]\n",
    "            length_previous = len(file_column_values)\n",
    "            file_column_values.extend(image_file_paths)\n",
    "            target_column_values.extend([target_dir] * len(image_file_paths))\n",
    "        df_return = pd.DataFrame(\n",
    "            list(zip(target_column_values, file_column_values)),\n",
    "            columns=[target_column, file_column],\n",
    "        )\n",
    "    else:\n",
    "        df_return = pd.read_csv(csv_file)\n",
    "        assert target_column in df_return.columns.values\n",
    "        assert file_column in df_return.columns.values\n",
    "    return df_return\n",
    "\n",
    "\n",
    "df_primary = init_dataframes(csv_paths[0], images_root_paths[0])\n",
    "df_secondary = pd.DataFrame(columns=df_primary.columns)\n",
    "print(f\"Columns: {list(df_primary.columns)}\")\n",
    "if 1 < len(images_root_paths) or 1 < len(csv_paths):\n",
    "    print(\"Using predefined testset\")\n",
    "    df_secondary = init_dataframes(csv_paths[-1], images_root_paths[-1])\n",
    "    assert list(df_primary.columns) == list(df_secondary.columns)\n",
    "print(f\"Total number of rows: {len(df_primary) + len(df_secondary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\datasets\\PlantVillage-Dataset\\raw\\color\\Apple___Apple_scab\\00075aa8-d81a-4184-8541-b692b78d398a___FREC_Scab 3335.JPG\n",
      "Merge by unique filepath\n",
      "0 rows could not be found\n",
      "0 rows could not be found\n"
     ]
    }
   ],
   "source": [
    "# df_primary[\"filepath\"] = df_primary\n",
    "sample = df_primary.iloc[0]\n",
    "sample[file_column]\n",
    "\n",
    "# sample_path = os.path.normpath(os.path.join(images_root_paths[0], sample[target_column], sample[file_column]))\n",
    "# if not os.path.exists(sample_path):\n",
    "print(sample[file_column])\n",
    "\n",
    "\n",
    "def merge_filepaths():\n",
    "    df_file = pd.DataFrame(\n",
    "        {\n",
    "            \"filepath\": list(existing_file_paths) + list(duplicates),\n",
    "            \"included\": np.concatenate(\n",
    "                [np.ones(len(existing_file_paths)), np.zeros(len(duplicates))]\n",
    "            ).astype(bool),\n",
    "        }\n",
    "    )\n",
    "    if (df_file[\"filepath\"] == sample[file_column]).any():\n",
    "        print(\"Merge by unique filepath\")\n",
    "\n",
    "        df_primary_extended = pd.merge(\n",
    "            df_primary, df_file, left_on=file_column, right_on=\"filepath\"\n",
    "        )\n",
    "        print(f\"{len(df_primary) - len(df_primary_extended)} rows could not be found\")\n",
    "\n",
    "        df_secondary_extended = pd.merge(\n",
    "            df_secondary, df_file, left_on=file_column, right_on=\"filepath\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{len(df_secondary) - len(df_secondary_extended)} rows could not be found\"\n",
    "        )\n",
    "        return df_primary_extended, df_secondary_extended\n",
    "\n",
    "    df_file[\"filename\"] = df_file[\"filepath\"].apply(lambda x: os.path.basename(x))\n",
    "    if not df_file[\"filename\"].is_unique:\n",
    "        print(\"A bit tricky case\")\n",
    "        print(df_file[df_file[\"filename\"].duplicated(False)])\n",
    "        return\n",
    "\n",
    "    if (df_file[\"filename\"] == sample[file_column]).any():\n",
    "        print(\"Merge by unique filename\")\n",
    "\n",
    "    elif df_file[\"filename\"].str.contains(sample[file_column]).sum():\n",
    "        print(\"Merge by substring\")\n",
    "        matching_filenames = df_file[\n",
    "            df_file[\"filename\"].str.contains(sample[file_column])\n",
    "        ][\"filename\"].values\n",
    "        if 1 < len(matching_filenames):\n",
    "            print(f\"Too many matches: {matching_filenames}\")\n",
    "            return\n",
    "        start_idx = matching_filenames[0].find(sample[file_column])\n",
    "        prefix = matching_filenames[0][:start_idx]\n",
    "        postfix = matching_filenames[0][start_idx + len(sample[file_column]) :]\n",
    "        df_primary[file_column] = prefix + df_primary[file_column] + postfix\n",
    "        df_secondary[file_column] = prefix + df_secondary[file_column] + postfix\n",
    "    else:\n",
    "        print(\"No merge found!\")\n",
    "        return\n",
    "\n",
    "    df_primary_extended = pd.merge(\n",
    "        df_primary, df_file, left_on=file_column, right_on=\"filename\"\n",
    "    )\n",
    "    print(f\"{len(df_primary) - len(df_primary_extended)} rows could not be found\")\n",
    "\n",
    "    df_secondary_extended = pd.merge(\n",
    "        df_secondary, df_file, left_on=file_column, right_on=\"filename\"\n",
    "    )\n",
    "    print(f\"{len(df_secondary) - len(df_secondary_extended)} rows could not be found\")\n",
    "    return df_primary_extended, df_secondary_extended\n",
    "\n",
    "\n",
    "df_primary_extended, df_secondary_extended = merge_filepaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 54263\n"
     ]
    }
   ],
   "source": [
    "df_primary = df_primary_extended[df_primary_extended[\"included\"]]\n",
    "df_secondary = df_secondary_extended[df_secondary_extended[\"included\"]]\n",
    "print(f\"Total number of rows: {len(df_primary) + len(df_secondary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stratify(groups, verbose=False):\n",
    "    for name, group in groups:\n",
    "        sub_groups = group.groupby(target_column)\n",
    "        for sub_name, sub_group in sub_groups:\n",
    "            if verbose:\n",
    "                print(f\"{name}: {sub_name}\")\n",
    "            if 1 < len(sub_groups):\n",
    "                print(\"Stratify not possible\")\n",
    "                print(group[[*group_columns, target_column]])\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "groups = None\n",
    "groupby_columns = [df_primary.index]\n",
    "if group_columns == []:\n",
    "    groups = df_primary.groupby(groupby_columns)\n",
    "    assert len(groups) == len(df_primary)\n",
    "else:\n",
    "    groupby_columns = group_columns\n",
    "    groups = df_primary.groupby(groupby_columns)\n",
    "    assert len(groups) < len(df_primary)\n",
    "stratify_possible = check_stratify(groups)\n",
    "\n",
    "if stratify_possible:\n",
    "    previous_length = len(groups)\n",
    "    groups = df_primary.groupby([*groupby_columns, target_column])\n",
    "    assert previous_length == len(groups)\n",
    "\n",
    "df_grouped = groups.size().reset_index()\n",
    "df_grouped.index = df_grouped[\"level_0\"]\n",
    "assert len(df_grouped.index) == len(groups.groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 43410\n",
      "Validation: 5426\n",
      "Test (without predefined): 5427\n"
     ]
    }
   ],
   "source": [
    "def split_sets(set_combined, split_ratio):\n",
    "    if 0 == split_ratio:\n",
    "        return set_combined, set_combined.iloc[:0, :].copy()\n",
    "\n",
    "    stratify_series = None\n",
    "    if stratify_possible:\n",
    "        stratify_series = set_combined[target_column]\n",
    "\n",
    "    return train_test_split(\n",
    "        set_combined, test_size=split_ratio, random_state=seed, stratify=stratify_series\n",
    "    )\n",
    "\n",
    "\n",
    "if 0 < len(df_secondary):\n",
    "    split_ratio_1 = (\n",
    "        split_ratio_1 * (1 - split_ratio_2) / (1 - split_ratio_1 * split_ratio_2)\n",
    "    )\n",
    "    split_ratio_2 = 0\n",
    "\n",
    "df_train, df_valid_test = split_sets(df_grouped, split_ratio_1)\n",
    "df_valid, df_test = split_sets(df_valid_test, split_ratio_2)\n",
    "\n",
    "train_ids = df_train[group_columns].values\n",
    "valid_ids = df_valid[group_columns].values\n",
    "test_ids = df_test[group_columns].values\n",
    "\n",
    "if group_columns == []:\n",
    "    train_ids = df_train.index.values\n",
    "    valid_ids = df_valid.index.values\n",
    "    test_ids = df_test.index.values\n",
    "\n",
    "print(f\"Training: {len(train_ids)}\")\n",
    "print(f\"Validation: {len(valid_ids)}\")\n",
    "print(f\"Test (without predefined): {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == len(np.intersect1d(train_ids, valid_ids))\n",
    "assert 0 == len(np.intersect1d(valid_ids, test_ids))\n",
    "assert 0 == len(np.intersect1d(test_ids, train_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_set(values):\n",
    "    group_id = tuple(values)\n",
    "    if 1 == len(group_id):\n",
    "        group_id = group_id[0]\n",
    "\n",
    "    if group_id in train_ids:\n",
    "        return \"train\"\n",
    "    elif group_id in valid_ids:\n",
    "        return \"valid\"\n",
    "    elif group_id in test_ids:\n",
    "        return \"test\"\n",
    "    else:\n",
    "        print(f\"Group_id '{group_id}' cannot be assigned\")\n",
    "        return None\n",
    "\n",
    "\n",
    "df_split = df_primary[[target_column, \"filepath\"]].copy()\n",
    "original_columns = df_split.columns\n",
    "df_split.columns = [\"target_code\", \"filepath\"]\n",
    "\n",
    "if group_columns == []:\n",
    "    df_split[\"set\"] = df_primary.index.to_frame().apply(get_set, axis=1)\n",
    "else:\n",
    "    df_split[\"set\"] = df_primary[groupby_columns].apply(get_set, axis=1)\n",
    "\n",
    "if 0 < len(df_secondary):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    df_split_test = df_secondary[original_columns]\n",
    "    df_split_test[\"set\"] = \"test\"\n",
    "    df_split_test.columns = df_split.columns\n",
    "    assert 0 == (df_split[\"set\"] == \"test\").sum()\n",
    "    df_split = pd.concat([df_split, df_split_test])\n",
    "\n",
    "print(set(df_split.index.unique()) ^ set(df_grouped.index.unique()))\n",
    "df_split[df_split[\"set\"].isnull()][\"filepath\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_code\n",
       "Apple___Apple_scab                                    0.011610\n",
       "Apple___Black_rot                                     0.011449\n",
       "Apple___Cedar_apple_rust                              0.005068\n",
       "Apple___healthy                                       0.030062\n",
       "Blueberry___healthy                                   0.027689\n",
       "Cherry_(including_sour)___Powdery_mildew              0.019396\n",
       "Cherry_(including_sour)___healthy                     0.015734\n",
       "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot    0.009445\n",
       "Corn_(maize)___Common_rust_                           0.021977\n",
       "Corn_(maize)___Northern_Leaf_Blight                   0.018152\n",
       "Corn_(maize)___healthy                                0.021424\n",
       "Grape___Black_rot                                     0.021746\n",
       "Grape___Esca_(Black_Measles)                          0.025478\n",
       "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)            0.019834\n",
       "Grape___healthy                                       0.007786\n",
       "Orange___Haunglongbing_(Citrus_greening)              0.101474\n",
       "Peach___Bacterial_spot                                0.042317\n",
       "Peach___healthy                                       0.006634\n",
       "Pepper,_bell___Bacterial_spot                         0.018383\n",
       "Pepper,_bell___healthy                                0.027229\n",
       "Potato___Early_blight                                 0.018429\n",
       "Potato___Late_blight                                  0.018429\n",
       "Potato___healthy                                      0.002810\n",
       "Raspberry___healthy                                   0.006842\n",
       "Soybean___healthy                                     0.093803\n",
       "Squash___Powdery_mildew                               0.033817\n",
       "Strawberry___Leaf_scorch                              0.020433\n",
       "Strawberry___healthy                                  0.008408\n",
       "Tomato___Bacterial_spot                               0.039208\n",
       "Tomato___Early_blight                                 0.018429\n",
       "Tomato___Late_blight                                  0.034877\n",
       "Tomato___Leaf_Mold                                    0.017554\n",
       "Tomato___Septoria_leaf_spot                           0.032642\n",
       "Tomato___Spider_mites Two-spotted_spider_mite         0.030891\n",
       "Tomato___Target_Spot                                  0.025870\n",
       "Tomato___Tomato_Yellow_Leaf_Curl_Virus                0.098710\n",
       "Tomato___Tomato_mosaic_virus                          0.006865\n",
       "Tomato___healthy                                      0.029095\n",
       "Name: filepath, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_split[df_split[\"set\"] == \"train\"]\n",
    "df_test.groupby(\"target_code\")[\"filepath\"].count() / len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_code\n",
       "Apple___Apple_scab                                    0.011611\n",
       "Apple___Black_rot                                     0.011426\n",
       "Apple___Cedar_apple_rust                              0.005160\n",
       "Apple___healthy                                       0.030041\n",
       "Blueberry___healthy                                   0.027645\n",
       "Cherry_(including_sour)___Powdery_mildew              0.019351\n",
       "Cherry_(including_sour)___healthy                     0.015850\n",
       "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot    0.009583\n",
       "Corn_(maize)___Common_rust_                           0.021931\n",
       "Corn_(maize)___Northern_Leaf_Blight                   0.018245\n",
       "Corn_(maize)___healthy                                0.021379\n",
       "Grape___Black_rot                                     0.021747\n",
       "Grape___Esca_(Black_Measles)                          0.025433\n",
       "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)            0.019720\n",
       "Grape___healthy                                       0.007925\n",
       "Orange___Haunglongbing_(Citrus_greening)              0.101548\n",
       "Peach___Bacterial_spot                                0.042388\n",
       "Peach___healthy                                       0.006635\n",
       "Pepper,_bell___Bacterial_spot                         0.018245\n",
       "Pepper,_bell___healthy                                0.027276\n",
       "Potato___Early_blight                                 0.018430\n",
       "Potato___Late_blight                                  0.018430\n",
       "Potato___healthy                                      0.002764\n",
       "Raspberry___healthy                                   0.006819\n",
       "Soybean___healthy                                     0.093808\n",
       "Squash___Powdery_mildew                               0.033727\n",
       "Strawberry___Leaf_scorch                              0.020457\n",
       "Strawberry___healthy                                  0.008478\n",
       "Tomato___Bacterial_spot                               0.039071\n",
       "Tomato___Early_blight                                 0.018430\n",
       "Tomato___Late_blight                                  0.034832\n",
       "Tomato___Leaf_Mold                                    0.017508\n",
       "Tomato___Septoria_leaf_spot                           0.032621\n",
       "Tomato___Spider_mites Two-spotted_spider_mite         0.030778\n",
       "Tomato___Target_Spot                                  0.025802\n",
       "Tomato___Tomato_Yellow_Leaf_Curl_Virus                0.098784\n",
       "Tomato___Tomato_mosaic_virus                          0.007003\n",
       "Tomato___healthy                                      0.029119\n",
       "Name: filepath, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid = df_split[df_split[\"set\"] == \"valid\"]\n",
    "df_valid.groupby(\"target_code\")[\"filepath\"].count() / len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_code\n",
       "Apple___Apple_scab                                    0.011609\n",
       "Apple___Black_rot                                     0.011424\n",
       "Apple___Cedar_apple_rust                              0.004975\n",
       "Apple___healthy                                       0.030035\n",
       "Blueberry___healthy                                   0.027640\n",
       "Cherry_(including_sour)___Powdery_mildew              0.019348\n",
       "Cherry_(including_sour)___healthy                     0.015662\n",
       "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot    0.009397\n",
       "Corn_(maize)___Common_rust_                           0.021927\n",
       "Corn_(maize)___Northern_Leaf_Blight                   0.018058\n",
       "Corn_(maize)___healthy                                0.021375\n",
       "Grape___Black_rot                                     0.021743\n",
       "Grape___Esca_(Black_Measles)                          0.025613\n",
       "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)            0.019900\n",
       "Grape___healthy                                       0.007739\n",
       "Orange___Haunglongbing_(Citrus_greening)              0.101529\n",
       "Peach___Bacterial_spot                                0.042381\n",
       "Peach___healthy                                       0.006633\n",
       "Pepper,_bell___Bacterial_spot                         0.018426\n",
       "Pepper,_bell___healthy                                0.027271\n",
       "Potato___Early_blight                                 0.018426\n",
       "Potato___Late_blight                                  0.018426\n",
       "Potato___healthy                                      0.002764\n",
       "Raspberry___healthy                                   0.006818\n",
       "Soybean___healthy                                     0.093790\n",
       "Squash___Powdery_mildew                               0.033905\n",
       "Strawberry___Leaf_scorch                              0.020453\n",
       "Strawberry___healthy                                  0.008292\n",
       "Tomato___Bacterial_spot                               0.039248\n",
       "Tomato___Early_blight                                 0.018426\n",
       "Tomato___Late_blight                                  0.035010\n",
       "Tomato___Leaf_Mold                                    0.017505\n",
       "Tomato___Septoria_leaf_spot                           0.032615\n",
       "Tomato___Spider_mites Two-spotted_spider_mite         0.030956\n",
       "Tomato___Target_Spot                                  0.025981\n",
       "Tomato___Tomato_Yellow_Leaf_Curl_Virus                0.098765\n",
       "Tomato___Tomato_mosaic_virus                          0.006818\n",
       "Tomato___healthy                                      0.029114\n",
       "Name: filepath, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_split[df_split[\"set\"] == \"test\"]\n",
    "df_test.groupby(\"target_code\")[\"filepath\"].count() / len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_root_path = images_root_paths[0]\n",
    "if 1 < len(images_root_paths):\n",
    "    images_root_path = os.path.commonpath(images_root_paths)\n",
    "df_split.to_csv(os.path.join(images_root_path, \"split.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_with_case_deviations = df_merged[df_merged[file_column].str.lower().duplicated(False)][file_column]\n",
    "# if 0 < len(files_with_case_deviations):\n",
    "#     print(files_with_case_deviations)\n",
    "#     assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def copy_wrapper(src, dst):\n",
    "#     if os.path.exists(dst):\n",
    "#         print(f\"Cannot copy from {src} to {dst}\")\n",
    "#         return\n",
    "#     return shutil.copy(src, dst)\n",
    "\n",
    "# if type(images_root_paths) is tuple:\n",
    "#     common_path = os.path.join(os.path.commonpath(images_root_paths), \"all/\")\n",
    "#     os.makedirs(common_path, exist_ok=False)\n",
    "#     shutil.copytree(images_root_paths[0], common_path, dirs_exist_ok=True, copy_function = copy_wrapper)\n",
    "#     shutil.copytree(images_root_paths[1], common_path, dirs_exist_ok=True, copy_function = copy_wrapper)\n",
    "#     images_root_paths = common_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not df_merged[file_column].is_unique:\n",
    "#     assert df_merged[[target_column,file_column]].apply(lambda x: os.path.join(*x), axis=1).is_unique\n",
    "#     df_primary[file_column] = df_primary[[target_column,file_column]].apply(lambda x: os.path.join(\"..\", *x), axis=1)\n",
    "#     assert df_primary[file_column].is_unique\n",
    "#     df_secondary[file_column] = df_secondary[[target_column,file_column]].apply(lambda x: os.path.join(\"..\", *x), axis=1)\n",
    "#     assert df_secondary[file_column].is_unique\n",
    "#     df_merged = pd.concat([df_primary, df_secondary])\n",
    "#     assert df_merged[file_column].is_unique\n",
    "\n",
    "# df_merged[[file_column, target_column]].groupby(target_column).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_existing_file(df):\n",
    "#     for image_path in df[df[target_column] == value][file_column]:\n",
    "#         image_name = os.path.basename(image_path)\n",
    "\n",
    "#         if not image_name in file_name_list:\n",
    "#             if not image_name in file_name_list:\n",
    "#             if image_name = image_name.replace(\"?\", \"\") # windows characters\n",
    "\n",
    "\n",
    "#         file_extension = os.path.splitext(image_name)[1]\n",
    "\n",
    "#         if file_extension == \"\":\n",
    "#             found_image_names = [\n",
    "#                 image_file_name\n",
    "#                 for image_file_name in image_file_names\n",
    "#                 if image_file_name.startswith(image_name)\n",
    "#             ]\n",
    "\n",
    "#             if 1 != len(found_image_names):\n",
    "#                 print(\n",
    "#                     f\"Image name '{image_name}' cannot be assigned to existing files: {found_image_names}\"\n",
    "#                 )\n",
    "#             assert 1 == len(found_image_names)\n",
    "#             image_name_new = found_image_names[0]\n",
    "#             df.loc[df[file_column] == image_name, [file_column]] = image_name_new\n",
    "#             image_name = image_name_new\n",
    "\n",
    "# if os.path.exists(source_path):\n",
    "#             else:\n",
    "#                 print(f\"Missing file: {source_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def copy_images_to_target_subdirectory(df):\n",
    "#     if csv_paths is None:\n",
    "#         return\n",
    "\n",
    "#     image_file_names = [\n",
    "#         name\n",
    "#         for name in os.listdir(path=images_root_paths)\n",
    "#         if os.path.isfile(os.path.join(images_root_paths, name))\n",
    "#     ]\n",
    "\n",
    "#     for value in df[target_column].unique():\n",
    "#         subdirectory = os.path.join(images_root_paths, target_column, str(value))\n",
    "#         print(f\"Copying to {subdirectory}\")\n",
    "#         os.makedirs(subdirectory, exist_ok=True)\n",
    "#         for image_path in df[df[target_column] == value][file_column]:\n",
    "#             image_name = os.path.basename(image_path)\n",
    "#             source_path = os.path.join(images_root_paths, image_name)\n",
    "#             if not os.path.exists(os.path.join(subdirectory, image_name)):\n",
    "#                 shutil.copy(source_path, f\"{subdirectory}/\")\n",
    "\n",
    "# copy_images_to_target_subdirectory(df_primary)\n",
    "\n",
    "# if df_secondary is not None:\n",
    "#     copy_images_to_target_subdirectory(df_secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example_images(title, image_paths):\n",
    "    number_of_columns = len(image_paths)\n",
    "    number_of_rows = len(image_paths[0])\n",
    "    fig, ax = plt.subplots(\n",
    "        number_of_columns,\n",
    "        number_of_rows,\n",
    "        figsize=(3 * number_of_rows, 3 * number_of_columns),\n",
    "        squeeze=False,\n",
    "    )\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    for row in range(len(image_paths)):\n",
    "        for column in range(len(image_paths[0])):\n",
    "            image_path = image_paths[row][column]\n",
    "            pil_im = Image.open(image_path, \"r\")\n",
    "            title = os.path.basename(image_path)\n",
    "            ax[row][column].imshow(pil_im)\n",
    "            ax[row][column].set_title(title)\n",
    "            ax[row][column].axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [\n",
    "    [\n",
    "        \"../datasets/HAM10000/images/ISIC_0033084.jpg\",\n",
    "        \"../datasets/HAM10000/images/ISIC_0033550.jpg\",\n",
    "        \"../datasets/HAM10000/images/ISIC_0033536.jpg\",\n",
    "    ],\n",
    "]\n",
    "# plot_example_images(\"HAM10000 examples\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: grouping is tricky. Examples:\n",
    "# PAT_1064_272_668, PAT_1064_273_980\n",
    "# PAT_759_1538_566, PAT_759_1433_914\n",
    "# PAT_1216_759_365, PAT_1216_759_542\n",
    "\n",
    "# Different lesions should not get mixed up\n",
    "# Sometimes different lesions have the same image\n",
    "\n",
    "# <patient_id>_<lesion_id>_<image_number>.png\n",
    "image_paths = [\n",
    "    [\n",
    "        \"../datasets/PAD-UFES-20/images/PAT_1064_273_980.png\",\n",
    "        \"../datasets/PAD-UFES-20/images/PAT_1064_272_668.png\",\n",
    "    ],\n",
    "    [\n",
    "        \"../datasets/PAD-UFES-20/images/PAT_1288_1003_553.png\",\n",
    "        \"../datasets/PAD-UFES-20/images/PAT_1288_1003_969.png\",\n",
    "    ],\n",
    "    [\n",
    "        \"../datasets/PAD-UFES-20/images/duplicates/images/PAT_38_1003_68.png\",\n",
    "        \"../datasets/PAD-UFES-20/images/duplicates/images/PAT_38_1003_226.png\",\n",
    "    ],\n",
    "    [\n",
    "        \"../datasets/PAD-UFES-20/images/duplicates/images/PAT_759_1538_566.png\",\n",
    "        \"../datasets/PAD-UFES-20/images/duplicates/images/PAT_759_1433_914.png\",\n",
    "    ],\n",
    "    [\n",
    "        \"../datasets/PAD-UFES-20/images/PAT_1216_759_365.png\",\n",
    "        \"../datasets/PAD-UFES-20/images/PAT_1216_759_542.png\",\n",
    "    ],\n",
    "]\n",
    "# plot_example_images(\"PAD-UFES-20 examples\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Only used to download Fitzpatrick17k images from original source, but many links are dead. It is better to download the dataset from the Google Drive.\n",
    "#\n",
    "# if \"url\" in df_primary.columns:\n",
    "#     for image_url in df_primary[\"url\"]:\n",
    "#         file_name = None\n",
    "#         if str(image_url) == \"nan\":\n",
    "#             # print(f\"image_url: {image_url}\")\n",
    "#             continue\n",
    "#         elif str(image_url).startswith(\"https://www.dermaamin.com\"):\n",
    "#             continue\n",
    "#         elif str(image_url).startswith(\"http://atlasdermatologico.com.br/img\"):\n",
    "#             continue\n",
    "\n",
    "#         file_name = os.path.basename(image_url)\n",
    "#         file_name = file_name.replace(\"?\", \"\")\n",
    "#         file_path = os.path.join(images_root_paths, file_name)\n",
    "\n",
    "#         if not os.path.exists(file_path):\n",
    "#             response = requests.get(\n",
    "#                 image_url, stream=True, headers={\"User-Agent\": \"XY\"}\n",
    "#             )\n",
    "#             if not response.ok:\n",
    "#                 print(f\"image_url: {image_url}\")\n",
    "#                 print(response)\n",
    "#                 continue\n",
    "\n",
    "#             with open(file_path, \"wb\") as handle:\n",
    "#                 for block in response.iter_content(1024):\n",
    "#                     if not block:\n",
    "#                         break\n",
    "#                     handle.write(block)\n",
    "# else:\n",
    "#     print(\"Skip download\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412f64844b7b8af74bdbb265a073648c443bf75ef51a1e949163ab9198702ceb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
