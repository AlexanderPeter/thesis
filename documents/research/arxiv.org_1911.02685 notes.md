# A Comprehensive Survey on Transfer Learning

23 Jun 2020

Transfer learning introduction

- Violin/piano, bicycle/moped
- negative transfer
- homogenous transfer (same feature space, but different distribution) vs heterogeneous transfer (different feature space)
- distribution adaption vs feature space adaption

"in transfer learning, the data distributions of the source and the target domains are usually different."

Semi-Supervised Learning: unlabeled and labeled data to train learner

Multi-View Learning: subspace learning, multi-kernel learning and co-training

Multi-Task Learning: some similar strategies as transfer learning

$D = \{X, P(X)\}$

$T = \{Y, f\}$

singlesource transfer learningvs multi-source transfer learning

transductive vs inductive vs unsupervised

instancebased, feature-based, parameter-based, and relational-based

"6.1 Medical Application
Medical imaging plays an important role in the medical
area, which is a powerful tool for diagnosis. With the development of computer technology such as machine learning, computer-aided diagnosis has become a popular and
promising direction. Note that medical images are generated by special medical equipment, and their labeling often
relies on experienced doctors. Therefore, in many cases, it is
expensive and hard to collect sufficient training data. Transfer learning technology can be utilized for medical imaging
analysis. A commonly used transfer learning approach is
to pre-train a neural network on the source domain (e.g.,
ImageNet, which is an image database containing more than
fourteen million annotated images with more than twenty
thousand categories \[166\]) and then finetune it based on the
instances from the target domain."

"the convolutional layers of AlexNet are fixed, and the last
three fully connected layers are replaced by the new ones
including one softmax layer, one fully connected layer, and
one output layer"
